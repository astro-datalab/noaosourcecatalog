#!/usr/bin/env python

import os
import sys
import numpy as np
import warnings
from astropy.table import Table
from astropy.io import fits
from astropy.utils.exceptions import AstropyWarning
import time
import shutil
import re
import subprocess
import glob
import logging
import socket
from datetime import datetime
from argparse import ArgumentParser
from dlnpyutils import job_daemon as jd
from nsc import utils
from nsc.nsc_instcal_measure import Exposure

# This drives many NSC jobs on a single slurm cluster node

if __name__ == "__main__":

    # Run measurement on one full DECam/Mosaic3/Bok InstCal image
    parser = ArgumentParser(description='Run multiple NSC jobs on a cluster node')
    parser.add_argument('tasksfile', type=str, nargs=1, help='Input list filename')
    parser.add_argument('version', type=str, nargs=1, help='NSC version')
    parser.add_argument('--host',type=str,nargs=1,default="None",help='hostname, default "None", other options supported are "cca","tempest_katie","tempest_group","gp09/7","tacc"')
    parser.add_argument('--staggertime',type=int,nargs=1,default=120,help='Stagger time.  Default is 120')
    parser.add_argument('--partition',type=str,nargs=1,default='normal',help='what TACC partition to use')
    parser.add_argument('--njobs',type=int,nargs=1,default=64,help='Number of jobs to run, default is 64')
    args = parser.parse_args()

    # Inputs
    tasksfile = args.tasksfile[0]
    version = args.version[0]                # NSC version, like "v4", default "None"
    if version=="None": version = None
    host = str(args.host[0])                 # hostname of server, default "None"                  
    if host=="None": host = None
    if isinstance(args.staggertime,list):
        staggertime = args.staggertime[0]
    else:
        staggertime = args.staggertime
    if isinstance(args.partition,list):
        partition = args.partition[0]
    else:
        partition = args.partition
    if isinstance(args.njobs,list):          # number of parallel jobs to run
        njobs = args.njobs[0]
    else:
        njobs = args.njobs

    t0 = time.time()
    
    print('Input Parameters:')
    print('-----------------')
    print('tasksfile =',tasksfile)
    print('version =',version)
    print('host =',host)    
    print('staggertime =',staggertime)
    print('partition =',partition)
    print('njobs = ',njobs)

    # Check that the input file exists
    if os.path.exists(tasksfile)==False:
        print(tasksfile,'NOT FOUND')
        sys.exit()

    # Input must be a tasks table fits file
    print('Loading',tasksfile)
    tasks = Table.read(tasksfile)
    print(len(tasks),'tasks')

    # Get NSC directories                                                                                     
    basedir, tmpdir = utils.getnscdirs(version,host)
    print("Working in basedir,tmpdir = ",basedir,tmpdir)
    # Make sure the directories exist                                                                         
    if not os.path.exists(basedir):
        os.makedirs(basedir)
    if not os.path.exists(tmpdir):
        os.makedirs(tmpdir)

    # Use job_daemon with delay/stagger time to allow for the files to
    # download before the next job is run

    jobs = jd.job_daemon(tasks['cmd'],tasks['dir'],tasks['name'],nmulti=njobs,
                         prefix='meas',hyperthread=True,waittime=100,
                         statustime=60,staggertime=staggertime)
    
    print("Total time = "+str(time.time()-t0)+" seconds")





