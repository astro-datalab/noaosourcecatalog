#!/usr/bin/env python

import os
import sys
import numpy as np
import warnings
from astropy.table import Table
from astropy.io import fits
from astropy.utils.exceptions import AstropyWarning
import time
import shutil
import re
import subprocess
import glob
import logging
import socket
from datetime import datetime
from argparse import ArgumentParser
from dlnpyutils import job_daemon as jd
from nsc.nsc_instcal_measure import getnscdirs,Exposure,download_from_archive

# This drives many NSC jobs on a single slurm cluster node

if __name__ == "__main__":

    # Run measurement on one full DECam/Mosaic3/Bok InstCal image
    parser = ArgumentParser(description='Run multiple NSC jobs on a cluster node')
    parser.add_argument('tasksfile', type=str, nargs=1, help='Input list filename')
    parser.add_argument('version', type=str, nargs=1, help='NSC version')
    parser.add_argument('--host',type=str,nargs=1,default="None",help='hostname, default "None", other options supported are "cca","tempest_katie","tempest_group","gp09/7","tacc"')
    parser.add_argument('--staggertime',type=int,nargs=1,help='Stagger time.  Default is 60')
    parser.add_argument('--partition',type=str,nargs=1,default='normal',help='what TACC partition to use')
    parser.add_argument('--njobs',type=int,nargs=1,default=64,help='Number of jobs to run, default is 64')
    parser.add_argument('--maxtasks',type=int,nargs=1,default=20000,help='Maximum number of tasks to run')
    parser.add_argument('-r','--redo', action='store_true', help='Redo exposures that were previously processed')
    args = parser.parse_args()

    # Inputs                                        
    stage = args.stage[0].lower()
    tasksfile = args.tasksfile[0]
    version = args.version[0]                # NSC version, like "v4", default "None"
    if version=="None": version = None
    host = str(args.host[0])                 # hostname of server, default "None"                  
    if host=="None": host = None
    if isinstance(args.staggertime,list):
        staggertime = args.staggertime[0]
    else:
        staggertime = args.staggertime
    if isinstance(args.partition,list):
        partition = args.partition[0]
    else:
        partition = args.partition
    if isinstance(args.njobs,list):          # number of parallel jobs to run
        njobs = args.njobs[0]
    else:
        njobs = args.njobs

    t0 = time.time()
    
    print('Input Parameters:')
    print('-----------------')
    print('stage =',stage,)
    print('tasksfile =',tasksfile)
    print('version =',version)
    print('host =',host)    
    print('staggertime =',staggertime)
    print('partition =',partition)
    print('njobs = ',njobs)

    # Check that the input file exists
    if os.path.exists(tasksfile)==False:
        print(tasksfile,'NOT FOUND')
        sys.exit()

    # Input must be a tasks table fits file
    print('Loading',tasksfile)
    tasks = Table.read(tasksfile)
    print(len(tasks),'tasks')

    # Get NSC directories                                                                                     
    basedir, tmpdir = getnscdirs(version,host)
    print("Working in basedir,tmpdir = ",basedir,tmpdir)
    # Make sure the directories exist                                                                         
    if not os.path.exists(basedir):
        os.makedirs(basedir)
    if not os.path.exists(tmpdir):
        os.makedirs(tmpdir)

    # Use job_daemon with delay/stagger time to allow for the files to
    # download before the next job is run

    jobs = jd.job_daemon(tasks['cmd'],tasks['dir'],tasks['name'],nmulti=njobs,
                         prefix='meas',hyperthread=True,waittime=100,statustime=60)


            # Need to download files on tempest
            #   use md5sum as filenames
            if host.startswith('tempest'):
                fluxfile = inputdata['fluxmd5sum'][i]
                wtfile = inputdata['wtmd5sum'][i]
                maskfile = inputdata['maskmd5sum'][i]
            # Check that all three files exist
            else:
                infiles = [fluxfile,wtfile,maskfile]
                exists = [os.path.exists(f) for f in infiles]
                bd, = np.where(np.array(exists)==False)
                if len(bd)>0:
                    print('Files not found: '+','.join(np.array(infiles)[bd])+'  SKIPPING')
                    continue
            #if base[:3] not in ['c4d','ksb','k4m']:
            #    print(base,'NOT in correct format. SKIPPING')
            #    continue
            instrument = base[:3]
            cmd = script+' '+fluxfile+' '+wtfile+' '+maskfile+' '+version
            if host:
                cmd += ' --host '+host
            if delete:
                cmd += ' --delete'
            # Check output filename
            if base[:3]=='c4d':
                night = '20'+base[4:10]
            else:
                instrument = 'c4d'  # assume decam for now
                if host.startswith('tempest'):
                    dateobs = inputdata['date_obs'][i]
                else:
                    head = fits.getheader(fluxfile,0)
                    dateobs = head['DATE-OBS']
                night = dateobs[:4]+dateobs[5:7]+dateobs[8:10]
    
    print("Total time = "+str(time.time()-t0)+" seconds")





